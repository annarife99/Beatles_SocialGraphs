{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3a0cfae",
   "metadata": {},
   "source": [
    "_**Social Graphs and Interactions** - Project Assignment B  | December 2021_\n",
    "\n",
    "Lluis Colomer - Anna Rif√©\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f16ab311",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All the necessary packages we used for this project\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.cm as cm\n",
    "import plotly.express as px\n",
    "import ast\n",
    "import operator\n",
    "import powerlaw\n",
    "from fa2 import ForceAtlas2\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "import urllib.request as urllib2\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.text import TextCollection\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import community.community_louvain\n",
    "import community.community_louvain\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1b5467",
   "metadata": {},
   "source": [
    "# <font color='darkgreen'> <center> <h3>The Network of Beatles Songs</h3> </center>\n",
    "# <font color='green'> <center> <h4>Getting into Beatles' mind</h4> </center>\n",
    "  \n",
    "![Image](https://github.com/annarife99/SocialGraphs-Project/blob/main/Images/Beatles.jpg?raw=true)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d8479c",
   "metadata": {},
   "source": [
    "**John Lennon**, **Paul McCartney**, **George Harrison** and **Ringo Starr**: The best-known members of the one of the greateast and most influential bands of all times: **The Beatles.** \n",
    "\n",
    "Smart, Idealistic, Playful, Irreverent, Eclectic, among many others. Their youth personification and unmatched innovation led their music, from the not-so-simple love songs they started with to their later perfectionistic studio extravaganzas. \n",
    "\n",
    "Led by primary songwriters Lennon and McCartney, the Beatles evolved from Lennon's previous group, and built their reputation playing clubs in Liverpool and Hamburg over three years from 1960. The core trio of Lennon, McCartney and Harrison, together since 1958, went through a succession of drummers, until Ringo Starr joined them in 1962. \n",
    "\n",
    "In the following years, the Beatles had an accomplished career, but mainly divided into three main periods of relatively similar productivity: the first stage started from the establishment of the band until their attaining worldwide popularity in 1964, the second was from 1965 to 1967 with the most creative and significant output of the group, and the final stage (from 1968 to 1970) where they were working more individually and the band finally folded in 1970. \n",
    "\n",
    "With this in mind, what has made us choose this current project and build the network of songs of one of the most influential bands of all times is presented below. \n",
    "\n",
    "\n",
    "## <font color='darkgreen'> 1. Motivation   \n",
    "No band has influenced pop culture the way The Beatles have. They were integral to the development of 1960s counterculture and popular music's recognition as an art form.\n",
    "        \n",
    "Currenly, after 50 years of their retirement from the stage and with more than 200 songs on streaming servies, The Beatles' Songs are still present on a daily basis, still catchy and played all over the world, remaining forever and likley to be  passing down from generation to generation. But...\n",
    "    \n",
    "#### <center> What do the Lyrics of Beatles' Songs hide ? </center>\n",
    "    \n",
    "Thrilled with the idea, performing different analyses based on the lyrics of Beatles could reveal many interesting hidden facts over the career of the band. \n",
    "    \n",
    "    \n",
    "### <font color='green'> 1.1 _Our Dataset:_\n",
    "All the data used in this project were mainly extracted from three different Web sites. Next, they are presented together with the code used to build the dataset. \n",
    "    \n",
    "**1)** **[The Beatles Wiki](https://beatles.fandom.com/wiki/The_Beatles_Wiki)**. It was created in 2006, and edited some years after, currently containing a total amount of 775 pages. It has represented our main source to extract the name of all Beatles released songs, representing the nodes of Beatles network. Addditionally, from each Wiki-page of each song, its released date, songwriter and its corresponding album were also extracted to be used as the node attributes of the network. <u>Section 1.4.1</u>  presents the code to obtain the API of the Wiki-Pages of each Beatles song, which were consequently stored in a txt. file to extract all the necessary information. \n",
    "Nevertheless, few Wiki-pages of each corresponding song had some features missing, reason why the following Web sites were used to counter that point. \n",
    "    \n",
    "**2)** **[The Beatles official Page](https://www.thebeatles.com/)**. It has been of great relevance to be able to extract reliable missing features from the Beatles-Wiki page and all the lyrics of their songs. The lyrics were then used to define the edges of the network under a specific criteria. In that way, <u>Section 1.4.2</u>  shows the code to obtain the API of the Beatles song from their official page to extract the lyrics, consequently stored in a txt. file. \n",
    "\n",
    "**3)** **[The Beatles Spotify Page](https://open.spotify.com/artist/3WrFJ7ztbogyGnTHbHJFl2)**. Their spotify profile was thought that could be used to find other minor attributes of each song related to music characterstics, such as the danceability, the key or tempo of each track. In Section <u>1.4.3</u>, we present how the API of the Beatles \n",
    "Spotify Page was obtained. \n",
    "\n",
    "After considerable data extraction from txt. file of the different sources, its consequent cleaning and preprocessing steps _(all detailed in Section 2)_, we ended up with a total number of **301 songs** to be able to build the most exiciting Beatles network of all times.     \n",
    "    \n",
    "### <font color='green'> 1.2 _Why?_\n",
    "After inspecting the literature, not many analysis have been focused on analyzing Beatles songs from a linguistic point of view, without revealing what makes their songs catchy and how they influenced each other. Fascinated by Beatles success and its music so many years after of their release, we were motivated enough to undertake the project of builing a network of Beatles songs and understand how could be related from a lyrics point of view. \n",
    "    \n",
    "#### <center> Could we get into Beatles'mind ? </center>\n",
    "    \n",
    "### <font color='green'> 1.3 _Our Goal:_\n",
    "The main aim of this project was to **build a Network of Beatles Songs** to be able to perform a deep analysis of the following points:\n",
    "    \n",
    "- Inspect how are Beatles songs related and inspired by each others, by also considering its songwritter. \n",
    "- Find communities of songs and their common particularities. \n",
    "- Perform a sentimental analysis to see which and how the most recurrent topics evoled over time. \n",
    "- Examine network growth to reveal Beatles' stages and their most inspirational years. \n",
    "    \n",
    "Overall, the current project could provide insights into songs and group dynamics of the Beatles and reveal many other features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b2e938",
   "metadata": {},
   "source": [
    "### <font color='green'> 1.4 _Code for Data Obtention:_\n",
    "\n",
    "#### <font color='green'> 1.4.1 _Data Extraction from The Beatles Wiki:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f15eaee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30270f8a",
   "metadata": {},
   "source": [
    "#### <font color='green'> 1.4.2 _Data Extraction from The Beatles Official Page:_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef75b9c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841ff0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have create a function to obtain the 'HTLM' of Beatles Official Page. \n",
    "def extract_html(url):\n",
    "    page = urlopen(url)\n",
    "    html_bytes = page.read()\n",
    "    html = html_bytes.decode(\"utf-8\")\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0acbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "years=[]\n",
    "months=[]\n",
    "days=[]\n",
    "\n",
    "for date in data0['Year']:\n",
    "    date=date.split(' ')\n",
    "    years.append(date[3])\n",
    "    months.append(date[2][:-1])\n",
    "    days.append(date[1][:-2])\n",
    "\n",
    "data11={'Song':songs_titles,'Year':years,'Month':months,'Day':days}\n",
    "data_df=pd.DataFrame(data11)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef06a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We obtain all the list of songs and we stored it in the Variable Songs_Titles\n",
    "pattern1= 'hreflang=\"en\">(.*?)</a>'\n",
    "pattern2= 'chronological-date\">(.*?)</td>'\n",
    "\n",
    "songs_titles=[]\n",
    "song_years=[]\n",
    "\n",
    "for i in range(0,9): \n",
    "    url = 'https://www.thebeatles.com/songs?page='+str(i)\n",
    "    html=extract_html(url)\n",
    "    a=re.findall(pattern1,html)\n",
    "    b=re.findall(pattern2,html)\n",
    "    \n",
    "    for el in a:\n",
    "        el=el.replace('&#039;', '\\'')\n",
    "        songs_titles.append(el)\n",
    "    \n",
    "    for el2 in b:\n",
    "        song_years.append(el2)\n",
    "\n",
    "print('The official Beatles page contains information of a number of' , len(songs_titles), 'songs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275a7c03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa412e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff898065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c46028df",
   "metadata": {},
   "source": [
    "#### <font color='green'> 1.4.3 _Data Extraction from The Beatles Spotify Page:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2449dc1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc535389",
   "metadata": {},
   "source": [
    "## <font color='darkgreen'> 2. Basic Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b66428",
   "metadata": {},
   "source": [
    "### <font color='green'> 2.1 _Data Cleaning and Preprocessing:_\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1a9714",
   "metadata": {},
   "source": [
    "### <font color='green'> 2.2 _Dataset Statistics:_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d0b680",
   "metadata": {},
   "source": [
    "From here a network has been created following the link criteria explained above (explicar part A del project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2976879b",
   "metadata": {},
   "source": [
    "## <font color='darkgreen'> 3. Tools, theory and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d87075f",
   "metadata": {},
   "source": [
    "- Talk about how you've worked with text, including regular expressions, unicode, etc.\n",
    "\n",
    "In order to accomplish one of the main goals of this project, that was connecting songs (nodes) between them depending on if they shared one at least of their common words according to tdf-if index, special emphasis has been put on text processing. Here we must distinguish between data extraction and preprocessing on one side, and sentimental analysis on the other. Let's focus now on the first part.\n",
    "\n",
    "For the purpose of getting all the needed data as explained in chapter 2, different kind of tools have been used.\n",
    "\n",
    "    -Regular expressions and unicode: (explicar els diferents patterns que hem utilitzat per extreure info de la \n",
    "    wiki i de la beatles page\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ea60dc",
   "metadata": {},
   "source": [
    "    - Cleaning lyrics\n",
    "    \n",
    "Once the lyrics had been extracted, it was needed to clean it as much as possible. With cleaning, it is meant deleting all those words and characters that do not add any special information to the text. It would not make sense to connect two songs just because they share a preposition or a conjunction, which are mainly the most common words in any language.\n",
    "\n",
    "Thus, in order to achive so, the _clean_lyrics( )_ function shown below has been created:\n",
    "\n",
    "`def clean_lyrics(file_path):\n",
    "    data=open(file_path).read()\n",
    "    # import WordPunctTokenizer() method from nltk\n",
    "    # Create a reference variable for Class WordPunctTokenizer\n",
    "    tk = WordPunctTokenizer()\n",
    "    # define punctuation\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    # remove punctuation from the string\n",
    "    no_punct = \"\"\n",
    "    for char in data:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char\n",
    "    # Remove all the special characters as \\n and single = left\n",
    "    char=['\\n','=']\n",
    "    for el in char:\n",
    "        raw=re.sub(el,'',no_punct)\n",
    "    # remove stop words\n",
    "    token_txt = tk.tokenize(raw.lower()) # set to lower case\n",
    "    token_txt = tk.tokenize(raw.lower()) # set to lower case\n",
    "    token_final = [x for x in token_txt if x not in stop_words and len(x)>2]\n",
    "    return token_final`\n",
    "\n",
    "What this function basically does is first clean and then tokenize the lyrics. To accomplish the cleaning part, first it removes any punctuation sign from the lyrics. Then it removes anys special characters that had been left when extracting it form the webpages api, such as _\\n_, =_ or empty spaces. Finally, it sets every word to lower case, and deletes all that ones that are not contained in the _nltk.corpus_ stopswords library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60327e13",
   "metadata": {},
   "source": [
    "    - tc, idf and tc_idf analysis\n",
    "\n",
    "To connect the links we decided to go a step further and establish the linking criteria not on which were the most common words from each song, but on which were the five words in each song with higher tc-idf score. To do so, basically tc and idf has been computed, to finally compute tc-idf for each word and each song while storing the values in a dictionary. Then the dicctionary was sorted according to its values, and thus the five words with higher tc-idf score values were picked for each song."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7169b10",
   "metadata": {},
   "source": [
    "    - creation of hyperlinks\n",
    "\n",
    "To create the hyperlinks a double loop has been created, iterating over all the songs. So, when the external loop picks a song, the inner loop iterates all over the songs, comparing each inner song with the external one. Thus, if between each pair of songs a word is shared, it is stored as they have equal word/s in common. Finally, to decide how the links are directioned, we pick the _Year_ attribute from both songs. Between each pair of songs, the song that was realeased earlier will point towards the other one.\n",
    "\n",
    "Once all this has been done, the network is created by using the _nx.DiGraph()_ command. Each song name is added as a node, an each link stored before is added as mentioned above. Finally, to perform a better analysis of how the songs are related with, the GCC component is extracted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da1b44e",
   "metadata": {},
   "source": [
    "    - Determining a criteria about which should be the accurate number of words chosen (no crec q calgui posar totes les imatges i si si, ho faria amb un subplot maybe)\n",
    "    \n",
    "To determine the criteria of how many words should be chosen according to the tc-idf score when establishing the links between nodes, an optimal point had to be found between prioratizing the threshold that gave us higher modularity when aiming to find communities in our songs, and obtaining a sufficient of nodes and links that makes the analysis of the network significant.\n",
    "\n",
    "To do so, a loop has been created to see how the network size and shape evolves as the number of words per song to establish the comparison increases.\n",
    "\n",
    "Threshold:  2\n",
    "<img src=\"https://github.com/annarife99/SocialGraphs-Project/blob/main/Images/fignet2.png?raw=true\" alt=\"drawing\" width=\"500\"/>\n",
    "- Considering the GCC of the Beatles Network, it has 9 number of nodes and 14 number of links.\n",
    "Number of communities found:  2\n",
    "The modularity value is: 0.263\n",
    "The distribution of the community sizes\n",
    "\n",
    "Threshold:  3\n",
    "<img src=\"https://github.com/annarife99/SocialGraphs-Project/blob/main/Images/fignet3.png?raw=true\" alt=\"drawing\" width=\"500\"/>\n",
    "- Considering the GCC of the Beatles Network, it has 70 number of nodes and 117 number of links.\n",
    "Number of communities found:  9\n",
    "The modularity value is: 0.723\n",
    "The distribution of the community sizes\n",
    "\n",
    "Threshold:  4\n",
    "<img src=\"https://github.com/annarife99/SocialGraphs-Project/blob/main/Images/fignet4.png?raw=true\" alt=\"drawing\" width=\"500\"/>\n",
    "- Considering the GCC of the Beatles Network, it has 132 number of nodes and 296 number of links.\n",
    "Number of communities found:  12\n",
    "The modularity value is: 0.700\n",
    "The distribution of the community sizes\n",
    "\n",
    "Threshold:  5\n",
    "<img src=\"https://github.com/annarife99/SocialGraphs-Project/blob/main/Images/fignet5.png?raw=true\" alt=\"drawing\" width=\"500\"/>\n",
    "- Considering the GCC of the Beatles Network, it has 174 number of nodes and 482 number of links.\n",
    "Number of communities found:  11\n",
    "The modularity value is: 0.596\n",
    "The distribution of the community sizes\n",
    "\n",
    "Threshold:  6\n",
    "<img src=\"https://github.com/annarife99/SocialGraphs-Project/blob/main/Images/fignet6.png?raw=true\" alt=\"drawing\" width=\"500\"/>\n",
    "- Considering the GCC of the Beatles Network, it has 184 number of nodes and 695 number of links.\n",
    "Number of communities found:  9\n",
    "The modularity value is: 0.507\n",
    "The distribution of the community sizes\n",
    "\n",
    "Threshold:  7\n",
    "<img src=\"https://github.com/annarife99/SocialGraphs-Project/blob/main/Images/fignet7.png?raw=true\" alt=\"drawing\" width=\"500\"/>\n",
    "- Considering the GCC of the Beatles Network, it has 189 number of nodes and 953 number of links.\n",
    "Number of communities found:  9\n",
    "The modularity value is: 0.435\n",
    "The distribution of the community sizes\n",
    "\n",
    "Threshold:  8\n",
    "<img src=\"https://github.com/annarife99/SocialGraphs-Project/blob/main/Images/fignet8.png?raw=true\" alt=\"drawing\" width=\"500\"/>\n",
    "- Considering the GCC of the Beatles Network, it has 193 number of nodes and 1248 number of links.\n",
    "Number of communities found:  10\n",
    "The modularity value is: 0.360\n",
    "The distribution of the community sizes\n",
    "\n",
    "Threshold:  9\n",
    "<img src=\"https://github.com/annarife99/SocialGraphs-Project/blob/main/Images/fignet9.png?raw=true\" alt=\"drawing\" width=\"500\"/>\n",
    "- Considering the GCC of the Beatles Network, it has 195 number of nodes and 1528 number of links.\n",
    "Number of communities found:  8\n",
    "The modularity value is: 0.320\n",
    "The distribution of the community sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c2cb95",
   "metadata": {},
   "source": [
    "**From the graphs and data plotted above, it has been decided to put the threshold at 5 words. Thus, achieving both a high level of modularity and a significant number of links and nodes when considering the GCC.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe188c2",
   "metadata": {},
   "source": [
    "- Describe which network science tools and data analysis strategies you've used, how those network science measures work, and why the tools you've chosen are right for the problem you're solving.\n",
    "\n",
    "        - Degree distributions:\n",
    "\n",
    "First, some basic stats of the network have been computed. Thus, total degree, in-degree and out-degree distributions are plotted below:\n",
    "\n",
    "<img src=\"https://github.com/annarife99/SocialGraphs-Project/blob/main/Images/Total_degree.png?raw=true\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "<img src=\"https://github.com/annarife99/SocialGraphs-Project/blob/main/Images/In_degree.png?raw=true\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "<img src=\"https://github.com/annarife99/SocialGraphs-Project/blob/main/Images/Out_degree.png?raw=true\" alt=\"drawing\" width=\"400\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079e2bfb",
   "metadata": {},
   "source": [
    "    - Finding communities\n",
    "In order to find communities inside the created network _community.community_louvain.best_partition()_ algorithm has been used. Thus the GCC of the beatles networks has been converted to undirected and inserted as an input to this algorithm. The results found show that 9 communities have been found, with a modularity value of 0.595.\n",
    "\n",
    "<img src=\"https://github.com/annarife99/SocialGraphs-Project/blob/main/Images/Communities_beatles.png?raw=true\" alt=\"drawing\" width=\"1500\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b826eef0",
   "metadata": {},
   "source": [
    "Separation between communities might be useful to analyze how songs are related between each other when establishing this linking method, and thus analyze which are the common characteristics and peculiarities of each community. First we started computing which were the most common words used in each community considering both the total number of words and the unique ones. Results are shown in the table below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b08dd41",
   "metadata": {},
   "source": [
    "|                             | Most common words (total number) |              |              |              |              | Most common unique words |            |            |             |             | Size of the community |\n",
    "|-----------------------------|:--------------------------------:|--------------|--------------|--------------|--------------|:------------------------:|------------|------------|-------------|-------------|-----------------------|\n",
    "| Comunity                    |                                  |              |              |              |              |                          |            |            |             |             |                       |\n",
    "|             0: little child |                       (come, 51) |   (know, 40) |  (honey, 32) |    (got, 31) | (things, 26) |               (know, 10) |  (love, 9) |  (like, 9) |    (say, 8) |    (got, 8) |                    21 |\n",
    "|                     1: girl |                       (girl, 93) | (better, 60) |    (let, 54) | (little, 53) |   (love, 48) |                (see, 12) | (love, 11) | (know, 11) |  (time, 11) |  (girl, 10) |                    26 |\n",
    "|                2: two of us |                        (way, 39) |   (home, 34) |    (two, 11) |    (work, 9) |    (back, 9) |                 (way, 3) |   (got, 2) |  (long, 2) | (sunday, 2) | (ticket, 2) |                     4 |\n",
    "|      3: i wanna be your man |                       (baby, 78) |   (know, 51) |    (man, 43) |   (said, 42) |   (want, 40) |               (know, 10) |  (baby, 8) |   (see, 8) |   (want, 8) |   (said, 7) |                    21 |\n",
    "|               4: love me do |                      (love, 156) |    (ill, 58) |   (mine, 46) |   (true, 27) |   (cant, 25) |               (love, 18) |  (ill, 11) | (know, 10) |    (see, 9) |   (want, 8) |                    30 |\n",
    "|         5: it won't be long |                      (yeah, 170) |   (long, 60) |   (know, 39) |    (sie, 24) |   (love, 23) |               (know, 12) | (yeah, 12) |   (day, 8) |   (long, 8) |   (well, 7) |                    22 |\n",
    "|            6: eleanor rigby |                       (know, 74) |   (name, 36) | (lonely, 28) |   (look, 27) | (number, 20) |                 (one, 5) |  (know, 5) | (going, 3) |   (time, 3) | (window, 3) |                     8 |\n",
    "|                     7: boys |                       (back, 39) |   (tell, 32) |   (goes, 26) |    (get, 22) |  (heart, 21) |                (back, 8) |  (time, 6) |  (away, 6) |    (ill, 6) |    (get, 5) |                    13 |\n",
    "| 8: i want to hold your hand |                       (love, 78) |    (say, 72) |   (know, 51) |   (good, 37) |  (hello, 35) |               (know, 17) | (love, 17) |  (say, 10) |   (like, 8) |   (time, 8) |                    29 |\n",
    "|                             |                                  |              |              |              |              |                          |            |            |             |             |                       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db413aa",
   "metadata": {},
   "source": [
    "Some first conclusions can be extracted from these communities. Although most of them share some of the most common words, some differences between them can be observed. For example in the community 4, including love me do song, love is the most used word, but ill, mine, true and cant are the other words. In contrast, in community 8, including I want to hold your hand song, although love is also the most used word, the other most common ones are say, know, good and hello. Despite this is not enough to affirm that there exist significant differences between the communities, the general perception about love seems to change, with a more sad-negative perspective in community 4 and a more optimistic-joyful love in the community 8.\n",
    "\n",
    "On the other hand, if we take a look in the unique words, in other words, in how many songs of the community a word appears, it is observed howthe most common ones are just present in half of the songs of the community, indicating that although there is a sense of belonging in each community, the partition is still far from being well done in terms of separating topics, and usually each community is a mix of different words-moods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c24dca0",
   "metadata": {},
   "source": [
    "    -  Sentimental Analysis: LabMT and VADER\n",
    "        - LabMT\n",
    "\n",
    "To compute the sentimental analysis for each community, LabMT method was used when dealing with cleaned lyrics that just contained the most important and characteristic words for each song. However, first it was needed to lemmatize, set to lower case, and tokenize the words so they will not be used twice. This was already implemented in clean_lyrics() function. \n",
    "\n",
    "In order to have a first visualization of the results a scatter plot was aimed, where the x-axis corresponded to the year and the y-axis to the mean labMT value per song. Moreover, each community would be represented with a specific colour. In order to achieve so, a dataframe was created, including the name of each song, the year, the labMT average value and the community it belonged to. Only songs that are in the GCC and in the Beatles Golden decade (1962-1970) have been included.\n",
    "\n",
    "Below, the results obtained with the labMT analysis can be observed (note that communities 2, 5 and 8 are not represented in this graph, meaning that when filtering by Year they have been taken out of the scope)\n",
    "\n",
    "<img src=\"https://github.com/annarife99/SocialGraphs-Project/blob/main/Images/LabMT_evolution.png?raw=true\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b788de34",
   "metadata": {},
   "source": [
    "It can be seen how there is not a clear tendency in the general mood of beatles songs as years pass by. According to LabMT analysis it could be said that Beatles songs tend to slightly increase its positivy as years go by, reaching its maximun average value at year 1968. From there, their positivity slightly decreases the last two years of this golden decade before their break-up at 1970.\n",
    "\n",
    "However, maybe an analysis with VADER makes more sense, due to the mood of the songs usually resides in how the sentence is written and not just in single words. So same procedure has been done but now computing the average sentimental value of each song according to VADER criteria. Due to a lot of neutral sentences were observed, two different graphs have been made. First one, considering all song sentences (more robust) and second one just considering these sentences that differ from neutral mood. These are the results obtained:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb6c57f",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/annarife99/SocialGraphs-Project/blob/main/Images/VADER_evolution.png?raw=true\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "<img src=\"https://github.com/annarife99/SocialGraphs-Project/blob/main/Images/VADER_without_neutral_evolution.png?raw=true\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c5ef4c",
   "metadata": {},
   "source": [
    "From the first graph, less conclusions can be extracted, just that the mood slightly decreases by year, due to it is mainly constant around an average VADER value around 0.1, which means that beatles songs tended to be more positive than negative at least.\n",
    "However, if a look is taken in the second graphs, some more interesting observations can be made. It still can be observed how the positivity of beatles slightly decrease during the first years of the decade, reaching an average VADER value of 0.2 between 1965-1966. From there, VADER average values slightly increases reaching a maximum around 1968-1969 before doing a significant decrease on 1970, the year of their break-up.\n",
    "\n",
    "Although LabMT and VADER graphs differ when showing the sentimental analysis of beatles songs by year, there a thing that can be observed in both graphs, and its this significant decrease in positivity in last year. Of course it is true that is not enough at all to affirm that, but this gives space for our imagination. Is this increase in negativity related with the fact that their break-up was just around the corner? Could the break-up of the beatles have been predicted and therefore tried to be avoided if sentimental analysis had been implemented and this decrease in positivity had been detected before it was too late?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278b1677",
   "metadata": {},
   "source": [
    "    -  Most recurrent topics over time\n",
    "\n",
    "<img src=\"https://github.com/annarife99/SocialGraphs-Project/blob/main/Images/comm_words_year.png?raw=true\" alt=\"drawing\" width=\"800\"/>\n",
    "    \n",
    "    - Evolution of songs including a specific word over the years\n",
    "    \n",
    "<img src=\"https://github.com/annarife99/SocialGraphs-Project/blob/main/Images/know.png?raw=true\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "<img src=\"https://github.com/annarife99/SocialGraphs-Project/blob/main/Images/love.png?raw=true\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "<img src=\"https://github.com/annarife99/SocialGraphs-Project/blob/main/Images/see.png?raw=true\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "<img src=\"https://github.com/annarife99/SocialGraphs-Project/blob/main/Images/time.png?raw=true\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "<img src=\"https://github.com/annarife99/SocialGraphs-Project/blob/main/Images/like.png?raw=true\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4ece81",
   "metadata": {},
   "source": [
    "- How did you use the tools to understand your dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b1953e",
   "metadata": {},
   "source": [
    "## <font color='darkgreen'> 4. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d9bde2",
   "metadata": {},
   "source": [
    "## <font color='darkgreen'> 5. Contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2c48c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
